{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Yellow Taxi Trip Records\n","\n","\n","In this notebook, we will perform the ETL process for the [Yellow Taxi Trip Records](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)."]},{"cell_type":"markdown","metadata":{},"source":["**Obs.:** To perform the data assessment, we will use the [Data Dictionary â€“ Yellow Taxi Trip Records](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf), provided by the TCL NYC Website. In this document, we will check the description of each field name, keeping in mind the possible values and range of values for each data field."]},{"cell_type":"markdown","metadata":{},"source":["## Step 1: Import Dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import datetime\n","import pyspark.sql.functions as f\n","from pyspark.sql.types import IntegerType"]},{"cell_type":"markdown","metadata":{},"source":["## Step 2: Load the Data\n","\n","Since the data has the same schema, we can easily perform: \n","\n","```spark.read()```\n","\n","And pass the folder to it:"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["df = spark.read.parquet(\"gs://mobilab-tech-task-bucket/yellow-taxi\")"]},{"cell_type":"markdown","metadata":{},"source":["We will also define the begin and the current year for future analysis"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["begin = 2020\n","\n","now = datetime.datetime.now()\n","until = now.year"]},{"cell_type":"markdown","metadata":{},"source":["## Step 3: Exploratory Data Analysis\n","\n","In order to get to know our data, we will perform a basic exploratory analysis of it:"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There is 81698054 rows in the dataframe\n"]}],"source":["print(f\"There is {df.count()} rows in the dataframe\")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- VendorID: long (nullable = true)\n"," |-- tpep_pickup_datetime: timestamp (nullable = true)\n"," |-- tpep_dropoff_datetime: timestamp (nullable = true)\n"," |-- passenger_count: double (nullable = true)\n"," |-- trip_distance: double (nullable = true)\n"," |-- RatecodeID: double (nullable = true)\n"," |-- store_and_fwd_flag: string (nullable = true)\n"," |-- PULocationID: long (nullable = true)\n"," |-- DOLocationID: long (nullable = true)\n"," |-- payment_type: long (nullable = true)\n"," |-- fare_amount: double (nullable = true)\n"," |-- extra: double (nullable = true)\n"," |-- mta_tax: double (nullable = true)\n"," |-- tip_amount: double (nullable = true)\n"," |-- tolls_amount: double (nullable = true)\n"," |-- improvement_surcharge: double (nullable = true)\n"," |-- total_amount: double (nullable = true)\n"," |-- congestion_surcharge: double (nullable = true)\n"," |-- airport_fee: integer (nullable = true)\n","\n"]}],"source":["df.printSchema()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+------------------+-----------------+-----------------+------------------+------------------+\n","|summary|   passenger_count|    trip_distance|     total_amount|      payment_type|        tip_amount|\n","+-------+------------------+-----------------+-----------------+------------------+------------------+\n","|  count|          78539123|         81698054|         81698054|          81698054|          81698054|\n","|   mean|1.4321764453621413|5.571054262810674|19.74366564854705|1.2040914830113334|2.3662261661738015|\n","| stddev|1.0405594659825625|573.4568144618119|226.0265670676297|0.5231703283378963| 2.902432948777313|\n","|    min|               0.0|           -30.62|          -2567.8|                 0|           -493.22|\n","|    max|             112.0|        357192.65|        1000003.8|                 5|           1400.16|\n","+-------+------------------+-----------------+-----------------+------------------+------------------+\n","\n"]}],"source":["df.select('passenger_count','trip_distance', 'total_amount', 'payment_type', 'tip_amount').describe().show()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+---------------------+\n","|tpep_pickup_datetime|tpep_dropoff_datetime|\n","+--------------------+---------------------+\n","| 2020-01-01 00:28:15|  2020-01-01 00:33:03|\n","| 2020-01-01 00:35:39|  2020-01-01 00:43:04|\n","| 2020-01-01 00:47:41|  2020-01-01 00:53:52|\n","| 2020-01-01 00:55:23|  2020-01-01 01:00:14|\n","| 2020-01-01 00:01:58|  2020-01-01 00:04:16|\n","| 2020-01-01 00:09:44|  2020-01-01 00:10:37|\n","| 2020-01-01 00:39:25|  2020-01-01 00:39:29|\n","| 2019-12-18 15:27:49|  2019-12-18 15:28:59|\n","| 2019-12-18 15:30:35|  2019-12-18 15:31:35|\n","| 2020-01-01 00:29:01|  2020-01-01 00:40:28|\n","+--------------------+---------------------+\n","only showing top 10 rows\n","\n"]}],"source":["df.select('tpep_pickup_datetime','tpep_dropoff_datetime').show(10)"]},{"cell_type":"markdown","metadata":{},"source":["**Issues**\n","\n","*   `trip_distance` < 0\n","*   `total_amount` < 0\n","*   `tip_amount` < 0\n","*   `passenger_count` > 10\n","* `tpep_pickup_datetime` < 2020\n","* `payment_type` out of the range\n","\n","\n","**Possible Issues**\n","\n","* `passenger_count` < 0\n","* `tpep_pickup_datetime` < 2020\n","* `lpep_dropoff_datetime` > 2022\n","* `tpep_dropoff_datetime` - `lpep_dropoff_datetime` < 0\n","\n","We will handle with this issues in the transformation step."]},{"cell_type":"markdown","metadata":{},"source":["## Step 4: Data Transformation\n","\n","Here, we will perform a series of data transformation methods, such as filtering, type conversion, row dropping, etc. Focus on building a more robust dataset."]},{"cell_type":"markdown","metadata":{},"source":["**Trip Distance Filtering**"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["df = df.filter('trip_distance >= 0')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.filter('trip_distance < 0').count()"]},{"cell_type":"markdown","metadata":{},"source":["**Passenger Count Filtering**"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+\n","|max(passenger_count)|\n","+--------------------+\n","|                 9.0|\n","+--------------------+\n","\n"]}],"source":["df = df.filter('passenger_count <= 10')\n","df.agg({'passenger_count': 'max' }).show()"]},{"cell_type":"markdown","metadata":{},"source":["**Total Amount Filtering**"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------+\n","|min(total_amount)|\n","+-----------------+\n","|              0.0|\n","+-----------------+\n","\n"]}],"source":["df = df.filter('total_amount >= 0')\n","df.agg({'total_amount': 'min' }).show()"]},{"cell_type":"markdown","metadata":{},"source":["**Tip Amount Filtering**"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+\n","|min(tip_amount)|\n","+---------------+\n","|            0.0|\n","+---------------+\n","\n"]}],"source":["df = df.filter('tip_amount >= 0')\n","df.agg({'tip_amount': 'min' }).show()"]},{"cell_type":"markdown","metadata":{},"source":["**Payment Type Analysis**\n","\n","Checkin wheater the payment is consistent with the total amount or not."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------+------------+\n","|total_amount|payment_type|\n","+------------+------------+\n","|         0.0|           2|\n","|         0.0|           2|\n","|         0.0|           2|\n","|         0.0|           2|\n","|         0.0|           2|\n","|         0.0|           2|\n","|         0.0|           2|\n","|         0.0|           2|\n","|         0.0|           2|\n","|         0.0|           2|\n","+------------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["df.select('total_amount','payment_type').filter('total_amount == 0 and payment_type != 3').show(10)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["16360"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df.filter('total_amount == 0 and payment_type != 3').count()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["df = df.withColumn(\"payment_type\", f.when(df[\"total_amount\"] == 0, 3).otherwise(df[\"payment_type\"]))\n","\n","df.filter('total_amount == 0 and payment_type != 3').count()"]},{"cell_type":"markdown","metadata":{},"source":["Replacing `0` value as `Nan` in `payment_type`, since is out of the range."]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df = df.withColumn(\"payment_type\", f.when(df[\"payment_type\"] == 0, np.nan).otherwise(df[\"payment_type\"]))\n","df.filter('payment_type == 0').count()"]},{"cell_type":"markdown","metadata":{},"source":["**Time Period**\n","\n","**Pickup Datetime**\n","\n","- 1.0 Checking wheater the `tpep_pickup_datetime` is in the range of years previously defined."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+\n","|tpep_pickup_datetime|\n","+--------------------+\n","| 2001-01-01 00:03:14|\n","| 2001-01-01 00:27:45|\n","| 2001-01-01 01:02:18|\n","| 2001-01-01 01:23:51|\n","| 2001-01-01 01:52:48|\n","+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["df.select('tpep_pickup_datetime').sort(f.col(\"tpep_pickup_datetime\")).show(5)"]},{"cell_type":"markdown","metadata":{},"source":["- 1.1 - Dropping the out of range rows"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["df = df.withColumn(\"year\", f.year(f.col(\"tpep_pickup_datetime\")))"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["df = df.filter(f'year >= {begin} and year <= {until}')\n","df = df.drop('year')"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+\n","|tpep_pickup_datetime|\n","+--------------------+\n","| 2020-01-01 00:00:00|\n","| 2020-01-01 00:00:00|\n","| 2020-01-01 00:00:00|\n","| 2020-01-01 00:00:00|\n","| 2020-01-01 00:00:00|\n","+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["df.select('tpep_pickup_datetime').sort(f.col(\"tpep_pickup_datetime\")).show(5)"]},{"cell_type":"markdown","metadata":{},"source":["**Dropoff Datetime**\n","\n","- 2.0 Checking wheater the `tpep_dropoff_datetime` is in the range of years previously defined."]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------+\n","|tpep_dropoff_datetime|\n","+---------------------+\n","|  2022-09-02 10:02:33|\n","|  2022-09-01 23:25:26|\n","|  2022-09-01 23:11:08|\n","|  2022-09-01 23:06:04|\n","|  2022-09-01 22:56:06|\n","+---------------------+\n","only showing top 5 rows\n","\n"]}],"source":["df.select('tpep_dropoff_datetime').sort(f.col(\"tpep_dropoff_datetime\").desc()).show(5)"]},{"cell_type":"markdown","metadata":{},"source":["In this particular case, the data frame already meets the requirement, but we will implement the filter thinking in future use cases."]},{"cell_type":"markdown","metadata":{},"source":["- 2.1 - Dropping the out of range rows"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["df = df.withColumn(\"year\", f.year(f.col(\"tpep_dropoff_datetime\")))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["df = df.filter(f'year >= {begin} and year <= {until}')\n","df = df.drop('year')"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------+\n","|tpep_dropoff_datetime|\n","+---------------------+\n","|  2022-09-02 10:02:33|\n","|  2022-09-01 23:25:26|\n","|  2022-09-01 23:11:08|\n","|  2022-09-01 23:06:04|\n","|  2022-09-01 22:56:06|\n","+---------------------+\n","only showing top 5 rows\n","\n"]}],"source":["df.select('tpep_dropoff_datetime').sort(f.col(\"tpep_dropoff_datetime\").desc()).show(5)"]},{"cell_type":"markdown","metadata":{},"source":["**Timestamps Analysis**\n","\n","The difference between `tpep_dropoff_datetime` and `tpep_pickup_datetime` must be greater than zero.\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["df = df.withColumn('DiffInSeconds', f.unix_timestamp(\"tpep_dropoff_datetime\") - f.unix_timestamp('tpep_pickup_datetime'))"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["df = df.filter('DiffInSeconds > 0')\n","df = df.drop('DiffInSeconds')"]},{"cell_type":"markdown","metadata":{},"source":["### 4.1: Timestamp Requirement\n","\n","Since the data science team wants to evaluate data also based on the hours and the day of the week, we could define two extra columns in our dataset.\n","\n","Our date and time values are already in a timestamp type, so it will be a quick transformation that will save the time of our team in the future."]},{"cell_type":"markdown","metadata":{},"source":["**Hours**\n","\n","On 24-hour time format."]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["df = df.withColumn(\"tpep_pickup_hour\", f.hour(f.col(\"tpep_pickup_datetime\"))) \\\n","       .withColumn(\"tpep_dropoff_hour\", f.hour(f.col(\"tpep_dropoff_datetime\")))"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------+-----------------+\n","|tpep_pickup_hour|tpep_dropoff_hour|\n","+----------------+-----------------+\n","|               0|                0|\n","|               0|                0|\n","|               0|                0|\n","|               0|                1|\n","|               0|                0|\n","+----------------+-----------------+\n","only showing top 5 rows\n","\n"]}],"source":["df.select('tpep_pickup_hour', 'tpep_dropoff_hour').show(5)"]},{"cell_type":"markdown","metadata":{},"source":["**Day of the week**\n","\n","This transformation will generate a column with the first three letters of the respective day of the week based on the timestamps."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["df = df.withColumn(\"pickup_day\", f.date_format('tpep_pickup_datetime', 'E')) \\\n","       .withColumn(\"dropoff_day\", f.date_format('tpep_dropoff_datetime', 'E'))"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------+----------+---------------------+-----------+\n","|tpep_dropoff_datetime|pickup_day|tpep_dropoff_datetime|dropoff_day|\n","+---------------------+----------+---------------------+-----------+\n","|  2020-01-01 00:33:03|       Wed|  2020-01-01 00:33:03|        Wed|\n","|  2020-01-01 00:43:04|       Wed|  2020-01-01 00:43:04|        Wed|\n","|  2020-01-01 00:53:52|       Wed|  2020-01-01 00:53:52|        Wed|\n","|  2020-01-01 01:00:14|       Wed|  2020-01-01 01:00:14|        Wed|\n","|  2020-01-01 00:04:16|       Wed|  2020-01-01 00:04:16|        Wed|\n","+---------------------+----------+---------------------+-----------+\n","only showing top 5 rows\n","\n"]}],"source":["df.select('tpep_dropoff_datetime','pickup_day', 'tpep_dropoff_datetime', 'dropoff_day').show(5)"]},{"cell_type":"markdown","metadata":{},"source":["## Step 5: Data Schema Check\n","\n","First, let us take a look on the actual data schema:"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- VendorID: long (nullable = true)\n"," |-- tpep_pickup_datetime: timestamp (nullable = true)\n"," |-- tpep_dropoff_datetime: timestamp (nullable = true)\n"," |-- passenger_count: double (nullable = true)\n"," |-- trip_distance: double (nullable = true)\n"," |-- RatecodeID: double (nullable = true)\n"," |-- store_and_fwd_flag: string (nullable = true)\n"," |-- PULocationID: long (nullable = true)\n"," |-- DOLocationID: long (nullable = true)\n"," |-- payment_type: double (nullable = true)\n"," |-- fare_amount: double (nullable = true)\n"," |-- extra: double (nullable = true)\n"," |-- mta_tax: double (nullable = true)\n"," |-- tip_amount: double (nullable = true)\n"," |-- tolls_amount: double (nullable = true)\n"," |-- improvement_surcharge: double (nullable = true)\n"," |-- total_amount: double (nullable = true)\n"," |-- congestion_surcharge: double (nullable = true)\n"," |-- airport_fee: integer (nullable = true)\n"," |-- tpep_pickup_hour: integer (nullable = true)\n"," |-- tpep_dropoff_hour: integer (nullable = true)\n"," |-- pickup_day: string (nullable = true)\n"," |-- dropoff_day: string (nullable = true)\n","\n"]}],"source":["df.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["Some data types above are weird, for example: `passenger_count` as a `double` (float).\n","\n","In the code cell below, we better define some data types for the final dataset schema."]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- VendorID: integer (nullable = true)\n"," |-- tpep_pickup_datetime: timestamp (nullable = true)\n"," |-- tpep_dropoff_datetime: timestamp (nullable = true)\n"," |-- passenger_count: integer (nullable = true)\n"," |-- trip_distance: double (nullable = true)\n"," |-- RatecodeID: double (nullable = true)\n"," |-- store_and_fwd_flag: string (nullable = true)\n"," |-- PULocationID: long (nullable = true)\n"," |-- DOLocationID: long (nullable = true)\n"," |-- payment_type: integer (nullable = true)\n"," |-- fare_amount: double (nullable = true)\n"," |-- extra: double (nullable = true)\n"," |-- mta_tax: double (nullable = true)\n"," |-- tip_amount: double (nullable = true)\n"," |-- tolls_amount: double (nullable = true)\n"," |-- improvement_surcharge: double (nullable = true)\n"," |-- total_amount: double (nullable = true)\n"," |-- congestion_surcharge: double (nullable = true)\n"," |-- airport_fee: integer (nullable = true)\n"," |-- tpep_pickup_hour: integer (nullable = true)\n"," |-- tpep_dropoff_hour: integer (nullable = true)\n"," |-- pickup_day: string (nullable = true)\n"," |-- dropoff_day: string (nullable = true)\n","\n"]}],"source":["df = df \\\n",".withColumn(\"VendorID\" ,df[\"VendorID\"].cast(IntegerType())) \\\n",".withColumn(\"passenger_count\" ,df[\"passenger_count\"].cast(IntegerType())) \\\n",".withColumn(\"payment_type\",df[\"payment_type\"].cast(IntegerType()))\n","\n","df.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["## Step 6: Data Transformation Check\n","\n","Now, we will perform the same exploratory data analysis that before, in order to evaluate the results of the data transformation step.\n","\n","The goal here is to confirm that we dealt properly with the spotted issues."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+------------------+------------------+------------------+-------------------+-----------------+\n","|summary|   passenger_count|     trip_distance|      total_amount|       payment_type|       tip_amount|\n","+-------+------------------+------------------+------------------+-------------------+-----------------+\n","|  count|          78103927|          78103927|          78103927|           78103927|         78103927|\n","|   mean|1.4326720601385383|3.0998538611251334|19.463213593572913|  1.242082360340217|2.374415468767291|\n","| stddev|1.0414274073772392|44.631973382627606| 231.1103016694798|0.44808221913761276|2.902552025221473|\n","|    min|                 0|               0.0|               0.0|                  1|              0.0|\n","|    max|                 9|          184340.8|         1000003.8|                  5|          1400.16|\n","+-------+------------------+------------------+------------------+-------------------+-----------------+\n","\n"]}],"source":["df.select('passenger_count','trip_distance', 'total_amount', 'payment_type', 'tip_amount').describe().show()"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+---------------------+\n","|tpep_pickup_datetime|tpep_dropoff_datetime|\n","+--------------------+---------------------+\n","| 2020-01-01 00:28:15|  2020-01-01 00:33:03|\n","| 2020-01-01 00:35:39|  2020-01-01 00:43:04|\n","| 2020-01-01 00:47:41|  2020-01-01 00:53:52|\n","| 2020-01-01 00:55:23|  2020-01-01 01:00:14|\n","| 2020-01-01 00:01:58|  2020-01-01 00:04:16|\n","+--------------------+---------------------+\n","only showing top 5 rows\n","\n"]}],"source":["df.select('tpep_pickup_datetime','tpep_dropoff_datetime').show(5)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There is 78103927 rows in the dataframe\n"]}],"source":["print(f\"There is {df.count()} rows in the dataframe\")"]},{"cell_type":"markdown","metadata":{},"source":["## Step 7: Outputs\n","\n","As the pipeline requirements, defined by our data science team, the output datasets are required in:\n","\n","1. **Colum-oriented format**\n","2. **Row-oriented format**\n","3. **Delta lake format**\n","\n","Since we are working in the Google Cloud (GC) platform, to meet the requirements will use the GC resources:\n","\n","1. **Colum-oriented format**\n","\n","     **No available due to versioning issues.**\n","\n","\n","2. **Row-oriented format**\n","\n","     **No available due to versioning issues.**\n","\n","In the above two topics, PySpark was not able to generate the files due to a versioning error. This error only appears in the Yellow Taxi Trip data, and the FHV Trip data. The Green and FHVHV data, even with the same function, do not have this problem.\n","\n","3. **Delta lake format**\n","\n","     **No available due to versioning issues.**\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}
